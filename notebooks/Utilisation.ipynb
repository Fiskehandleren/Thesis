{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Change this vvvvvvv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER = \"WEBSTER\"\n",
    "model = 'TGCN'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge models trained on other censoring strategies into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def add_censoring_strategy_predictions(df=None, censoring_level=1, censoring_strategy=\"Static\", keep_obs=False, prefix='best_sweep'):\n",
    "    directory_path = f\"../predictions/{prefix}_{model.lower()}_{censoring_strategy.lower()}_{censoring_level}\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise NotADirectoryError(directory_path)\n",
    "\n",
    "    preds_path = glob(f\"{directory_path}/predictions_{model}_{CLUSTER}*.csv\")[0] \n",
    "    df_preds = pd.read_csv(preds_path, parse_dates=[\"Date\"], index_col=0)\n",
    "\n",
    "    # Because we HAD a bug of double predictions being generated\n",
    "    df_preds.dropna(inplace=True)\n",
    "\n",
    "    # Assume we have forecast horizon of 1. Then we rename the columns to something more readable\n",
    "    df_preds.rename(columns={\n",
    "        CLUSTER+\"_1\": f\"Censored Observations {censoring_strategy} {censoring_level}\",\n",
    "        CLUSTER+\"_1_pred\": f\"Predicted {censoring_strategy} {censoring_level}\",\n",
    "        f\"{CLUSTER}_1_true\": f\"True Observations\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    if not keep_obs:\n",
    "        df_preds = df_preds.drop(f\"True Observations\", axis=1)\n",
    "\n",
    "    if df is None:\n",
    "        return df_preds\n",
    "    return df.merge(df_preds, on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_censoring_strategy_predictions(None, 2, \"Dynamic\", keep_obs=True)\n",
    "df = add_censoring_strategy_predictions(df, 1, \"Dynamic\")\n",
    "df = add_censoring_strategy_predictions(df, 2, \"Static\")\n",
    "df = add_censoring_strategy_predictions(df, 3, \"Static\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge cluster capacity data onto the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug_capacity = pd.read_csv(\"../data/MaximumPlugsPerCluster.csv\", index_col=0, parse_dates=[\"StartDate\", \"EndDate\"])\n",
    "plug_capacity = plug_capacity[['StartDate', 'EndDate', 'Cluster', 'No. Plugs per Hub']]\n",
    "plug_capacity = plug_capacity[plug_capacity.Cluster != 'SHERMAN']\n",
    "plug_capacity = plug_capacity[plug_capacity.Cluster == CLUSTER]\n",
    "plug_capacity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, set the last occurence's EndDate to be the last date in the dataset\n",
    "clusters = plug_capacity['Cluster'].unique()\n",
    "last_date = df.reset_index()['Date'].max()\n",
    "\n",
    "# Update the last occurrence's EndDate for each cluster\n",
    "for cluster in clusters:\n",
    "    last_occurrence_index = plug_capacity[plug_capacity['Cluster'] == cluster].index[-1]\n",
    "    plug_capacity.loc[last_occurrence_index, 'EndDate'] = last_date\n",
    "plug_capacity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with a daily date range\n",
    "start_date = plug_capacity['StartDate'].min()\n",
    "end_date = plug_capacity['EndDate'].max()\n",
    "daily_dates = pd.date_range(start_date, end_date, freq='D')\n",
    "daily_df = pd.DataFrame({'Date': daily_dates})\n",
    "\n",
    "# Merge the original DataFrame with the new DataFrame\n",
    "merged_df = pd.merge_asof(daily_df, plug_capacity, left_on='Date', right_on='StartDate', direction='forward')\n",
    "\n",
    "# Forward fill the missing values in the 'Cluster' and 'No. Plugs per Hub' columns\n",
    "merged_df[['Cluster', 'No. Plugs per Hub']] = merged_df[['Cluster', 'No. Plugs per Hub']].ffill()\n",
    "\n",
    "# Fill the remaining NaN values in the 'No. Plugs per Hub' column with the first available value (backwards fill)\n",
    "merged_df['No. Plugs per Hub'] = merged_df['No. Plugs per Hub'].bfill()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "result_df = merged_df.drop(['StartDate', 'EndDate'], axis=1)\n",
    "result_df = result_df[result_df.Cluster == CLUSTER]\n",
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge cluster capacities onto the prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge_asof(df, result_df, on=\"Date\", direction=\"nearest\")\n",
    "df.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relevant_cols = lambda censoring_level, censoring_strategy: [\n",
    "        'Date', 'No. Plugs per Hub', \"True Observations\",\n",
    "        f\"Censored Observations {censoring_strategy} {censoring_level}\", f\"Predicted {censoring_strategy} {censoring_level}\"]\n",
    "\n",
    "def plot_predictions(df, censoring_level, censoring_strategy):\n",
    "    # Keep only relevant columns\n",
    "    df_plot = df.copy()[get_relevant_cols(censoring_level, censoring_strategy)]\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    ax.axhline(y=df_plot[df_plot.Date < '2019-05-30'][f'Censored Observations {censoring_strategy} {censoring_level}'].max(), linestyle='--', label='Censored Threshold', color='black', )\n",
    "    df_plot[df_plot.Date < '2019-05-30']\\\n",
    "        .drop('No. Plugs per Hub', axis=1)\\\n",
    "        .drop(f\"Censored Observations {censoring_strategy} {censoring_level}\", axis=1)\\\n",
    "        .plot(x=\"Date\", ax=ax, title=f\"{model} Predictions for {CLUSTER} cluster with censoring strategy {censoring_strategy} {censoring_level}\", ylabel='Number of sessions', colormap='tab10')\n",
    "\n",
    "    # Set horizontal line at the maximum number of plugs\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"../Figures/prediction_timeseries_{model}_{CLUSTER}_{censoring_strategy}_{censoring_level}.png\")\n",
    "    plt.show()\n",
    "plot_predictions(df, 2, \"Dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_max_sessions(df, censoring_level, censoring_strategy):\n",
    "    df_plot = df.copy()[get_relevant_cols(censoring_level, censoring_strategy)]\n",
    "    # Plot the highest prediction for each day, together with the highest recorded simultaneous number of sessions in a time interval\n",
    "    fig, ax = plt.subplots(figsize=(20, 7))\n",
    "    ax.axhline(y=df_plot[df_plot.Date < '2019-05-30'][f'Censored Observations {censoring_strategy} {censoring_level}'].max(), linestyle='--', label='Censored Threshold', color='black', )\n",
    "    df_plot\\\n",
    "        .drop('No. Plugs per Hub', axis=1) \\\n",
    "        .drop(f\"Censored Observations {censoring_strategy} {censoring_level}\", axis=1) \\\n",
    "        .groupby(df_plot[\"Date\"].dt.date).max() \\\n",
    "        .plot(x=\"Date\", ax=ax, title=f\"Max number of sessions for each day in cluster {CLUSTER}\", colormap='tab10')\n",
    "    ax.set_title(f\"Max number of sessions for each day in cluster {CLUSTER}\")\n",
    "    ax.set_ylabel(\"Number of sessions\")\n",
    "    plt.show()\n",
    "\n",
    "plot_daily_max_sessions(df, 2, \"Dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_utilisation_per_day(df, censoring_level, censoring_strategy):\n",
    "    df_util_plot = df.copy()\n",
    "    cols = get_relevant_cols(censoring_level, censoring_strategy)\n",
    "    cols.remove('Date')\n",
    "    cols.remove('No. Plugs per Hub')\n",
    "    # We should provide tau from the model training\n",
    "    for col in cols:\n",
    "        df_util_plot['tau_'+col] = df_util_plot[col].max()\n",
    "\n",
    "    sessions_per_day = df_util_plot.groupby(df_util_plot[\"Date\"].dt.date).sum().copy()\n",
    "\n",
    "    # Calculate utilisation\n",
    "    for col in cols:\n",
    "        sessions_per_day['utilisation_'+col] = sessions_per_day[col] / sessions_per_day['No. Plugs per Hub']\n",
    "    # Plot\n",
    "    # drop all tau columns\n",
    "    sessions_per_day = sessions_per_day[sessions_per_day.columns[sessions_per_day.columns.str.startswith('utilisation_')]]\n",
    "    # remove utilisation_ from the column names\n",
    "    sessions_per_day.columns = sessions_per_day.columns.str.replace('utilisation_', '')\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    sessions_per_day.plot(ax=ax, colormap='tab10')\n",
    "\n",
    "    ax.set_title(f\"Utilisation per day in cluster {CLUSTER}\")\n",
    "    ax.set_ylabel(\"Utilisation\")\n",
    "    fig.savefig(f\"../Figures/daily_utilisation_{model}_{CLUSTER}_{censoring_strategy}_{censoring_level}.png\")\n",
    "\n",
    "plot_utilisation_per_day(df, 2, \"Dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utilisation_per_day(df, 2, \"Static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_utility(df, max_tau, censoring_level, censoring_strategy):\n",
    "    \"\"\" \n",
    "    Calulcate the utility for a given cluster, given predictions, censored and true values of usage, for taus from 1 - max_tau.\n",
    "    \"\"\"\n",
    "    cols = get_relevant_cols(censoring_level, censoring_strategy)\n",
    "    cols.remove('Date')\n",
    "    cols.remove('No. Plugs per Hub')\n",
    "    util_values = {level: [] for level in cols}\n",
    "    # calculate the utility for predicted usage, true usage and censored usage, for each tau\n",
    "    for level, util_list in util_values.items():\n",
    "        for tau_hypothetical in range(1, max_tau + 1):\n",
    "            df_util = df.copy()\n",
    "            # clip the values to the hypothetical tau (we use values from df instead of df_util to avoid clipping the values multiple times)\n",
    "            df_util[level] = df[level].clip(upper=tau_hypothetical)\n",
    "            # add the tau_hypothetical as a column\n",
    "            df_util[f'tau_{tau_hypothetical}'] = tau_hypothetical\n",
    "            # Sum the half-hourly values to get the daily values\n",
    "            tmp = df_util.groupby(df_util[\"Date\"].dt.date)[[level, f'tau_{tau_hypothetical}']].sum()\n",
    "            # calculate the utility per day\n",
    "            tmp['utilisation'] = (tmp[level] / tmp[f'tau_{tau_hypothetical}'])\n",
    "            # add the mean utility to the list\n",
    "            util_list.append(tmp['utilisation'].mean())\n",
    "\n",
    "    return util_values\n",
    "utility_values = calculate_utility(df, 12, 2, \"Dynamic\")\n",
    "pd.DataFrame(utility_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_utility(df, max_tau, censoring_level, censoring_strategy, ax=None):\n",
    "    utility_values = calculate_utility(df, max_tau, censoring_level, censoring_strategy)\n",
    "    df_utilisation = pd.DataFrame(utility_values)\n",
    "    df_utilisation['Capacity'] = df_utilisation.index + 1\n",
    "    capacity = df['No. Plugs per Hub'].max()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 8), sharey=True)\n",
    "        # Only plot true observations if nothing else is plotted yet\n",
    "        # Plot observed demand\n",
    "        line, =  ax.plot(\n",
    "            df_utilisation[df_utilisation.Capacity <= capacity]['Capacity'],\n",
    "            df_utilisation[df_utilisation.Capacity <= capacity][\"True Observations\"],\n",
    "            linestyle='-', marker='o', label=\"Utilisation for true demand\"\n",
    "        )\n",
    "        color = line.get_color()\n",
    "        ax.plot(\n",
    "            df_utilisation[df_utilisation.Capacity >= capacity]['Capacity'],\n",
    "            df_utilisation[df_utilisation.Capacity >= capacity][\"True Observations\"],\n",
    "            linestyle='dashed', marker='o', color=color, alpha=0.5\n",
    "        )\n",
    "        fig.suptitle(f\"Predicted vs observed utilisation for cluster {CLUSTER} for different capacities\")\n",
    "\n",
    "    max_observed_by_model = 0\n",
    "    if censoring_strategy == \"Dynamic\":\n",
    "        max_observed_by_model = capacity - censoring_level\n",
    "    else:\n",
    "        max_observed_by_model = censoring_level\n",
    "\n",
    "    # Plot predicted demand\n",
    "    \n",
    "    line, = ax.plot(\n",
    "        df_utilisation[df_utilisation.Capacity <= max_observed_by_model]['Capacity'],\n",
    "        df_utilisation[df_utilisation.Capacity <= max_observed_by_model][f\"Predicted {censoring_strategy} {censoring_level}\"],\n",
    "        linestyle='-', marker='o', label=f\"Utilisation for predicted demand {censoring_strategy} {censoring_level}\"\n",
    "    )\n",
    "    color = line.get_color()\n",
    "    ax.plot(\n",
    "        df_utilisation[df_utilisation.Capacity >= max_observed_by_model]['Capacity'],\n",
    "        df_utilisation[df_utilisation.Capacity >= max_observed_by_model][f\"Predicted {censoring_strategy} {censoring_level}\"],\n",
    "        linestyle='dashed', marker='o', color=color, alpha=0.5\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Capacity\")\n",
    "    ax.set_ylabel(\"Utilisation\")\n",
    "    ax.yaxis.set_tick_params(labelleft=True)\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_utility(df, 12, 1, \"Dynamic\")\n",
    "ax = plot_utility(df, 12, 2, \"Dynamic\", ax=ax)\n",
    "ax = plot_utility(df, 12, 2, \"Static\", ax=ax)\n",
    "ax = plot_utility(df, 12, 3, \"Static\", ax=ax)\n",
    "\n",
    "\n",
    "ax.axhline(y=0.2, linestyle='--', color='g', label=\"20% utilisation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization is key (PWC)\n",
    "Once an EV-charging station is built, all costs are essentially fixed, so utilization is key to achieving efficiency. Still, even a quite low utilization is likely to result in lines at busy times. In practice, the stand-alone, fast-charger industry uses a 20% utilization as a rule of thumb. But if a charging station is utilized at more than this 20% threshold, the operator will likely look to expand capacity or, more likely, add another site nearby."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24 hours forecast lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_48 = add_censoring_strategy_predictions(None, 2, \"Dynamic\", keep_obs=True, prefix=\"forecast_48\")\n",
    "df_48 = add_censoring_strategy_predictions(df_48, 1, \"Dynamic\", prefix=\"forecast_48\")\n",
    "df_48 = add_censoring_strategy_predictions(df_48, 2, \"Static\", prefix=\"forecast_48\")\n",
    "df_48 = add_censoring_strategy_predictions(df_48, 3, \"Static\", prefix=\"forecast_48\")\n",
    "\n",
    "df_48 = pd.merge_asof(df_48, result_df, on=\"Date\", direction=\"nearest\")\n",
    "\n",
    "df_48.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily_max_sessions(df_48, 2, \"Dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_values = calculate_utility(df_48, 12, 2, \"Dynamic\")\n",
    "ax = plot_utility(df_48, 12, 1, \"Dynamic\")\n",
    "ax = plot_utility(df_48, 12, 2, \"Dynamic\", ax=ax)\n",
    "ax = plot_utility(df_48, 12, 2, \"Static\", ax=ax)\n",
    "ax = plot_utility(df_48, 12, 3, \"Static\", ax=ax)\n",
    "\n",
    "\n",
    "ax.axhline(y=0.2, linestyle='--', color='g', label=\"20% utilisation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unc_i = add_censoring_strategy_predictions(None, 2, \"Dynamic\", keep_obs=True, prefix=\"uncertainty_1_forecast_1\")\n",
    "df_unc_i = add_censoring_strategy_predictions(df_unc_i, 2, \"Dynamic\", prefix=\"uncertainty_2_forecast_1\")\n",
    "df_unc_i = add_censoring_strategy_predictions(df_unc_i, 2, \"Dynamic\", prefix=\"uncertainty_3_forecast_1\")\n",
    "df_unc_i = add_censoring_strategy_predictions(df_unc_i, 2, \"Dynamic\", prefix=\"uncertainty_4_forecast_1\")\n",
    "df_unc_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
