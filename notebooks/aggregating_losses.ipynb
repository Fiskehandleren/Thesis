{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_agg = ['test_loss', 'test_loss_true', 'test_mae', 'test_mse']\n",
    "clusters = ['WEBSTER', 'HIGH', 'TED', 'HAMILTON', 'RINCONADA', 'CAMBRIDGE', 'MPL', 'BRYANT']\n",
    "data_path = \"../data/LossCSVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_csv(model, lead, strategy, censor_level):\n",
    "    base_name = f\"{data_path}/loss_{model}lead{lead}_{strategy}{censor_level}\"\n",
    "\n",
    "    aware_path = f\"{base_name}.csv\"\n",
    "    unaware_path = f\"{base_name}_unaware.csv\"\n",
    "\n",
    "    if not os.path.exists(aware_path):\n",
    "        print(f\"Warning: Missing data for aware {model} {lead} {strategy}{censor_level}.Path {aware_path} does not exist\")\n",
    "        raise FileNotFoundError\n",
    "    if not os.path.exists(unaware_path):\n",
    "        print(f\"Warning: Missing data for unaware {model} {lead} {strategy}{censor_level}.Path {unaware_path} does not exist\")\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    aware_df = pd.read_csv(aware_path)\n",
    "    unaware_df = pd.read_csv(unaware_path)\n",
    "    return aware_df[aware_df.State != 'crashed'], unaware_df[unaware_df.State != 'crashed']\n",
    "\n",
    "def calculate_losses(df, df_unaware, model_name, columns_to_agg):\n",
    "    agg_mean = np.round(df[columns_to_agg].mean(),2)\n",
    "    agg_std = np.round(df[columns_to_agg].std(),2)\n",
    "\n",
    "    agg_mean_unaware = np.round(df_unaware[columns_to_agg].mean(),2)\n",
    "    agg_std_unaware = np.round(df_unaware[columns_to_agg].std(),2)\n",
    "\n",
    "    losses = [model_name.upper()]\n",
    "    for col in columns_to_agg:\n",
    "        # Unaware models don't have a censored loss\n",
    "        if col == 'test_loss':\n",
    "            losses.append('$' + agg_mean[col].astype(str) + r' \\pm ' + agg_std[col].astype(str) + '$ / -')\n",
    "        else:\n",
    "            losses.append('$' + agg_mean[col].astype(str) + r' \\pm ' + agg_std[col].astype(str) + '$ / $' + agg_mean_unaware[col].astype(str) + r' \\pm ' + agg_std_unaware[col].astype(str) + '$')\n",
    "    return losses\n",
    "\n",
    "leads = [1, 48]\n",
    "strategies = {\n",
    "    'dyn': [1, 2],\n",
    "    'stat': [2, 3]\n",
    "}\n",
    "\n",
    "models = ['gru', 'lstm', 'ar']\n",
    "leads = [1, 48]\n",
    "\n",
    "# Store the dataframes in a dictionary\n",
    "\n",
    "# Iterate over all the combinations\n",
    "df_losses = pd.DataFrame(columns=['Forecast lead', 'Model', 'Strategy'] + columns_to_agg)\n",
    "\n",
    "no_runs_dict = {}\n",
    "\n",
    "for lead in leads:\n",
    "    for strategy, censor_levels in strategies.items():\n",
    "        for censor_level in censor_levels:\n",
    "            for model in models:\n",
    "                # Load data\n",
    "                try:\n",
    "                    aware, unaware = load_csv(model, lead, strategy, censor_level)\n",
    "                except:\n",
    "                    continue\n",
    "                # Figure out how many runs we have\n",
    "                no_runs_aware = np.floor(aware.shape[0]/8)\n",
    "                no_runs_unaware = np.floor(unaware.shape[0]/8)\n",
    "                print(f\"Model {model} lead {lead} strategy {strategy} censor level {censor_level} has {no_runs_aware} aware runs and {no_runs_unaware} unaware runs\")\n",
    "                # Take the first no_runs runs\n",
    "                aware = aware.groupby('cluster').head(no_runs_aware).copy()\n",
    "                unaware = unaware.groupby('cluster').head(no_runs_unaware).copy()\n",
    "\n",
    "                aware.loc[:, \"run_no\"] = np.repeat(np.arange(1, 1+no_runs_aware), 8)\n",
    "                unaware.loc[:, \"run_no\"] = np.repeat(np.arange(1, 1+no_runs_unaware), 8)\n",
    "                # Mean over runs\n",
    "                unaware_agg = unaware.groupby('run_no').mean().reset_index()\n",
    "                aware_agg = aware.groupby('run_no').mean().reset_index()\n",
    "                df_losses.loc[len(df_losses)] = [lead, strategy+ str(censor_level)] + calculate_losses(aware_agg, unaware_agg, model, columns_to_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
